import math
import pandas as pd
import numpy as np
from numpy.random import rand
import matplotlib.pyplot as plt

from descender import descend


def h(x, p):
	"""[5 points] return a linear function of x, with
	x -- an input vector representing one instance in the data space, where len(x) = len(p) - 1
	p -- the parameters of linear function, where p[0] is the coefficent of x[0] etc. and p[-1] is the bias parameter.
	"""
	

def g(p, x_batch, y_batch):
	"""[5 points] return the gradient of the error function on h for parameter list p
	p -- the parameters of linear function, where p[0] is the coefficent of x[0] etc. and p[-1] is the bias parameter.
	x_batch -- a matrix representing a batch of input the data space, where len(x) = len(p) - 1
	y_batch -- the (real number) label associated with the items in the data batch
	"""
	

"""[5 points] extract test and train data and labels. the first argument in each line is the label (y).
	the remaining arguments are the input data (x) 
"""

"""[5 points] randomly initialize your parameter vector
"""

"""[5 points] Run descent for 0, 5, 100, 200, and 1600 iterations on the training data only. 
[5 points] On both the test and training data, graph sse against each of these running times
"""

	
	








